**How to Run:**
- download Ollama: https://ollama.com/

**On the Windows Powershell:**
The least resource consuming model:
- ollama run llama3.2:1b
- ollama serve (if error stating port already in use, then proceed with next command, as ollama is already running)
- ollama pull llama3 


  

